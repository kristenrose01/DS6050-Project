{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting Breast Tissue Abnormalities in Mammograms through Deep Learning\n",
        "DS 6050: Project Milestone II  \n",
        "Project Group 4: Stephanie Landas (sfl7ck), Kristen Rose (krr4de), Michelle Wu (mw3ef)"
      ],
      "metadata": {
        "id": "1mCBRVBFuSYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as tr\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "EfUaeAUnLYNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in csv"
      ],
      "metadata": {
        "id": "vn30juP7Ap6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lnlsy0rvA8MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/drive/MyDrive/DS6050 (Deep Learning) Project/Data\"\n",
        "train_csv_path = os.path.join(root, \"csv\", \"mass_case_description_train_set.csv\")\n",
        "test_csv_path = os.path.join(root, \"csv\", \"mass_case_description_test_set.csv\")\n",
        "images = os.path.join(root, \"jpeg\")"
      ],
      "metadata": {
        "id": "nDMCuIy1Avmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = pd.read_csv(train_csv_path)\n",
        "test_csv = pd.read_csv(test_csv_path)"
      ],
      "metadata": {
        "id": "RDFd309CIOOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View one image of each type"
      ],
      "metadata": {
        "id": "TbIKxNllId6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benign_img_path = train_csv.loc[train_csv['pathology'] == \"BENIGN\"].iloc[[0]]\\\n",
        "['image file path'].values[0]\n",
        "benign_img = Image.open(os.path.join(images, benign_img_path.split(\"/\")[-2], \\\n",
        "os.listdir(os.path.join(images, benign_img_path.split(\"/\")[-2]))[0])).convert(\"RGB\")\n",
        "plt.imshow(benign_img)\n",
        "plt.title(\"benign\");\n",
        "plt.show()\n",
        "\n",
        "benign_no_callback_img_path = train_csv.loc[train_csv['pathology'] == \"BENIGN_WITHOUT_CALLBACK\"].iloc[[0]]\\\n",
        "['image file path'].values[0]\n",
        "benign_no_callback_img = Image.open(os.path.join(images, benign_no_callback_img_path.split(\"/\")[-2], \\\n",
        "os.listdir(os.path.join(images, benign_no_callback_img_path.split(\"/\")[-2]))[0])).convert(\"RGB\")\n",
        "plt.imshow(benign_no_callback_img)\n",
        "plt.title(\"benign no callback\");\n",
        "plt.show()\n",
        "\n",
        "malignant_img_path = train_csv.loc[train_csv['pathology'] == \"MALIGNANT\"].iloc[[0]]\\\n",
        "['image file path'].values[0]\n",
        "malignant_img = Image.open(os.path.join(images, malignant_img_path.split(\"/\")[-2], \\\n",
        "os.listdir(os.path.join(images, malignant_img_path.split(\"/\")[-2]))[0])).convert(\"RGB\")\n",
        "plt.imshow(malignant_img)\n",
        "plt.title(\"malignant\");\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gk58qj9LIdOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "oavIQe07IsAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "val_data = []\n",
        "\n",
        "for index, row in train_csv.iterrows():\n",
        "  path = f\"{row['image file path'].split('/')[-2]}\"\n",
        "  if(index < np.round(len(train_csv)*0.85)):\n",
        "    train_data.append(os.path.join(images, path, \\\n",
        "    f\"{row['pathology']}_{os.listdir(os.path.join(images, row['image file path'].split('/')[-2]))[0]}\"))\n",
        "  else:\n",
        "    val_data.append(os.path.join(images, path, \\\n",
        "    f\"{row['pathology']}_{os.listdir(os.path.join(images, row['image file path'].split('/')[-2]))[0]}\"))\n",
        "\n",
        "print(f\"train data: {len(train_data)}, val data: {len(val_data)}\")"
      ],
      "metadata": {
        "id": "dlTy3NHVOgGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "  def __init__(self, image_paths, class_dict, transforms):\n",
        "    self.paths = image_paths\n",
        "    self.class_dict = class_dict\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path = self.paths[idx]\n",
        "    actual_path = f\"{'/'.join(path.split('/')[:-1])}/{os.path.basename(path)[:-4].split('_')[-1]}.jpg\"\n",
        "    pil_img = Image.open(actual_path).convert(\"RGB\")\n",
        "    tensor = self.transforms(pil_img)\n",
        "    label = os.path.basename(path)[:-4].split(\"_\")[0]\n",
        "    if(label == \"BENIGN\" or label == \"BENIGN_NO_CALLBACK\"):\n",
        "      label = \"not_cancer\"\n",
        "    else:\n",
        "      label = \"cancer\"\n",
        "    label = self.class_dict[label]\n",
        "    return tensor, label\n"
      ],
      "metadata": {
        "id": "FUIWPDf3cs_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "6o7JRdjXI97f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "class_dict = {\"cancer\": 0, \"not_cancer\": 1}\n",
        "transforms = tr.Compose([tr.ToTensor(), tr.Resize((1024, 1024), antialias = True), tr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_dataloader = DataLoader(dataset=ClassifierDataset(image_paths=train_data, class_dict=class_dict, transforms=transforms),\n",
        "                              batch_size=batch_size,\n",
        "                              num_workers=0,\n",
        "                              shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=ClassifierDataset(image_paths=val_data, class_dict=class_dict, transforms=transforms),\n",
        "                              batch_size=batch_size,\n",
        "                              num_workers=0,\n",
        "                              shuffle=True)\n",
        "dataloader_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n"
      ],
      "metadata": {
        "id": "k0tebIh0lbIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "PLAPLIsfJNad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.00001\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "acxJu60XrkaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in pretrained model"
      ],
      "metadata": {
        "id": "YikzpHHzJTeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights)\n",
        "model_name = \"effnet_classify_breast_cancer\"\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lmsYZLEsJLO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "metrics = {\"epoch\": [], \"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "best_loss = np.inf\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch}\")\n",
        "  for phase in [\"train\", \"val\"]:\n",
        "    if(phase == \"train\"):\n",
        "      model.train()\n",
        "    else:\n",
        "      model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0.0\n",
        "    loader = dataloader_dict[phase]\n",
        "    for inputs, labels in tqdm(loader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(phase == \"train\"):\n",
        "        outputs = model(inputs).to(device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "      if(phase == \"train\"):\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = running_loss/len(dataloader_dict[phase].dataset)\n",
        "    epoch_acc = running_correct/len(dataloader_dict[phase].dataset)\n",
        "    print(f\"{phase}; Loss: {epoch_loss}, Acc: {epoch_acc}\")\n",
        "\n",
        "    if(phase == \"train\"):\n",
        "      metrics[\"epoch\"].append(epoch)\n",
        "      metrics[\"train_loss\"].append(epoch_loss)\n",
        "      metrics[\"train_acc\"].append(epoch_acc)\n",
        "    else:\n",
        "      metrics[\"val_loss\"].append(epoch_loss)\n",
        "      metrics[\"val_acc\"].append(epoch_acc)\n",
        "\n",
        "    if(epoch_loss < best_loss and phase == \"val\"):\n",
        "      best_loss = epoch_loss\n",
        "      torch.save(model, f\"/content/drive/MyDrive/DS6050 (Deep Learning) Project/model - efficientnet/{model_name}_best_model.pth\")\n",
        "\n",
        "    torch.save(model, f\"/content/drive/MyDrive/DS6050 (Deep Learning) Project/model - efficientnet/history/{model_name}_epoch{epoch}.pth\")\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/DS6050 (Deep Learning) Project/model - efficientnet/metrics.pkl\", 'wb') as handle:\n",
        "      pickle.dump(metrics, handle)\n",
        "\n"
      ],
      "metadata": {
        "id": "tZ12qYsvqZ2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference/ Evaluation results"
      ],
      "metadata": {
        "id": "aTOB0uNaJYJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "class_dict = {\"cancer\": 0, \"not_cancer\": 1}\n",
        "transforms = tr.Compose([tr.ToTensor(), tr.Resize((1024, 1024), antialias = True), tr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n"
      ],
      "metadata": {
        "id": "hlG7Camp008J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "\n",
        "for index, row in test_csv.iterrows():\n",
        "  path = f\"{row['image file path'].split('/')[-2]}\"\n",
        "  test_data.append(os.path.join(images, path, \\\n",
        "  f\"{row['pathology']}_{os.listdir(os.path.join(images, row['image file path'].split('/')[-2]))[0]}\"))\n",
        "\n",
        "\n",
        "print(f\"test data: {len(test_data)}\")\n",
        "\n",
        "test_dataloader = DataLoader(dataset=ClassifierDataset(image_paths=test_data, class_dict=class_dict, transforms=transforms),\n",
        "                             batch_size=1,\n",
        "                             num_workers=0,\n",
        "                             shuffle=True)"
      ],
      "metadata": {
        "id": "3COMlCACz18Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path  = \"/content/drive/MyDrive/DS6050 (Deep Learning) Project/model - efficientnet/effnet_classify_breast_cancer_best_model.pth\"\n",
        "model = torch.load(model_path, map_location=device)\n",
        "model = model.eval()"
      ],
      "metadata": {
        "id": "BqSHVhESxxMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "actuals = []\n",
        "for inputs, labels in tqdm(test_dataloader):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  output = model(inputs)\n",
        "  pred = torch.argmax(output, dim=1).cpu().detach().numpy()\n",
        "  preds.append(pred)\n",
        "  actuals.append(labels.cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "oo1sPhrswlw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = metrics.recall_score(actuals, preds, average=\"micro\")\n",
        "precision = metrics.precision_score(actuals, preds, average=\"micro\")\n",
        "print(f\"recall: {recall}\")\n",
        "print(f\"precision: {precision}\")"
      ],
      "metadata": {
        "id": "Qi538BRQ211Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = metrics.confusion_matrix(actuals, preds, normalize=\"true\")\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=list(class_dict.keys()))\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1pBZMJD3EL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}